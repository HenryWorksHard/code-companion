<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <style>
    * { margin: 0; padding: 0; }
    html, body { height: 100%; }
    body { background: transparent; overflow: hidden; }
    canvas { display: block; }
  </style>
</head>
<body>
  <canvas id="canvas"></canvas>
  
  <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/pixi.js@6.5.10/dist/browser/pixi.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display@0.4.0/dist/cubism4.min.js"></script>
  
  <script>
    window.addEventListener('load', async () => {
      if (typeof PIXI === 'undefined' || !PIXI.live2d) {
        console.error('Libraries not loaded');
        return;
      }

      const canvas = document.getElementById('canvas');
      const canvasWidth = 350;
      const canvasHeight = 650;
      
      const app = new PIXI.Application({
        view: canvas,
        width: canvasWidth,
        height: canvasHeight,
        backgroundAlpha: 0,
        resolution: window.devicePixelRatio || 1,
        autoDensity: true,
      });

      try {
        const baseUrl = window.location.href.replace('viewer.html', '');
        
        // Load body model first (behind)
        const bodyModel = await PIXI.live2d.Live2DModel.from(baseUrl + 'body/model.model3.json', {
          autoInteract: false,
          autoUpdate: true,
        });
        
        // Load head model second (on top)
        const headModel = await PIXI.live2d.Live2DModel.from(baseUrl + 'head/model.model3.json', {
          autoInteract: false,
          autoUpdate: true,
        });
        
        // Scale and position body
        const bodyScale = 0.058;
        bodyModel.scale.set(bodyScale);
        bodyModel.anchor.set(0.5, 0.5);
        bodyModel.position.set(canvasWidth / 2, canvasHeight / 2 + 40);
        
        // Scale and position head (sits on top of body)
        const headScale = 0.058;
        headModel.scale.set(headScale);
        headModel.anchor.set(0.5, 0.5);
        headModel.position.set(canvasWidth / 2, 380);
        
        // Add body first, then head on top
        app.stage.addChild(bodyModel);
        app.stage.addChild(headModel);
        
        // Get the core model for parameter control
        const coreModel = headModel.internalModel.coreModel;
        
        // Lip sync state
        let isSpeaking = false;
        let mouthOpenTarget = 0;
        let currentMouthOpen = 0;
        
        // Animate mouth smoothly
        const animateMouth = () => {
          // Smooth interpolation
          currentMouthOpen += (mouthOpenTarget - currentMouthOpen) * 0.3;
          
          // Set mouth parameter
          const paramIndex = coreModel.getParameterIndex('ParamMouthOpenY');
          if (paramIndex >= 0) {
            coreModel.setParameterValueByIndex(paramIndex, currentMouthOpen);
          }
          
          requestAnimationFrame(animateMouth);
        };
        animateMouth();
        
        // Simulate talking animation during speech
        let talkInterval = null;
        const startTalking = () => {
          isSpeaking = true;
          // Randomize mouth movement to simulate natural speech
          talkInterval = setInterval(() => {
            if (isSpeaking) {
              mouthOpenTarget = 0.3 + Math.random() * 0.7; // Random between 0.3-1.0
            }
          }, 100); // Update every 100ms
        };
        
        const stopTalking = () => {
          isSpeaking = false;
          if (talkInterval) {
            clearInterval(talkInterval);
            talkInterval = null;
          }
          mouthOpenTarget = 0;
        };
        
        // Browser Speech Synthesis
        const speak = (text) => {
          // Cancel any ongoing speech
          window.speechSynthesis.cancel();
          
          const utterance = new SpeechSynthesisUtterance(text);
          
          // Try to find a nice female voice
          const voices = window.speechSynthesis.getVoices();
          const femaleVoice = voices.find(v => 
            v.name.includes('Female') || 
            v.name.includes('Samantha') || 
            v.name.includes('Karen') ||
            v.name.includes('Victoria') ||
            v.name.includes('Google UK English Female')
          ) || voices.find(v => v.lang.startsWith('en')) || voices[0];
          
          if (femaleVoice) {
            utterance.voice = femaleVoice;
          }
          
          utterance.rate = 1.0;
          utterance.pitch = 1.1;
          
          utterance.onstart = () => {
            startTalking();
            window.parent.postMessage({ type: 'speech-start' }, '*');
          };
          
          utterance.onend = () => {
            stopTalking();
            window.parent.postMessage({ type: 'speech-end' }, '*');
          };
          
          utterance.onerror = () => {
            stopTalking();
            window.parent.postMessage({ type: 'speech-error' }, '*');
          };
          
          window.speechSynthesis.speak(utterance);
        };
        
        // Smooth mouse tracking with easing
        let targetX = canvasWidth / 2;
        let targetY = canvasHeight / 2;
        
        const updateFocus = () => {
          headModel.focus(targetX, targetY);
          requestAnimationFrame(updateFocus);
        };
        updateFocus();
        
        // Mouse tracking
        document.addEventListener('mousemove', (e) => {
          targetX = e.clientX;
          targetY = e.clientY;
        });
        
        // Handle messages from parent window 
        window.addEventListener('message', (e) => {
          if (e.data?.type === 'mousemove') {
            targetX = e.data.x;
            targetY = e.data.y;
          } else if (e.data?.type === 'speak') {
            speak(e.data.text);
          } else if (e.data?.type === 'stop-speaking') {
            window.speechSynthesis.cancel();
            stopTalking();
          }
        });

        // Click for expression (head model has expressions)
        document.addEventListener('click', () => {
          const exprs = headModel.internalModel.motionManager?.expressionManager?.definitions;
          if (exprs?.length) {
            headModel.expression(Math.floor(Math.random() * exprs.length));
          }
        });

        // Load voices (needed for some browsers)
        window.speechSynthesis.getVoices();
        
        window.parent.postMessage({ type: 'live2d-loaded' }, '*');
        
      } catch (err) {
        console.error('Live2D error:', err);
        window.parent.postMessage({ type: 'live2d-error', error: err.message }, '*');
      }
    });
  </script>
</body>
</html>
